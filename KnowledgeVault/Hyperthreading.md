# Hyperthreading

Some [[Pipelined CPU]]s are capable of issuing instructions [[Out-of-Order Execution|out of order]] as a means of reducing [[Pipeline Stalls]]. Normally a pipelined CPU executes instructions in program order; but sometimes the next instruction in the instruction stream cannot be issued due to a dependency on an in-flight instruction. This creates a delay slot into which another instruction could theoretically be issued. An OOO(out of order execution) CPU can “look ahead” in the instruction stream and select an instruction to issue out-of-order into such a delay slot.

With only a single instruction stream, the CPU’s options are somewhat limited when selecting an instruction to issue into a delay slot. But what if the CPU could select its instructions from two separate instruction streams at once? This is the principle behind a <mark style="background: #D2B3FFA6;">hyperthreaded (HT) CPU core</mark>. Technically speaking, an HT core consists of two [[Register files]] and two instruction decode units, but with a single “back end” for executing instructions, and a single shared [[Memory Cache|L1 cache]]. This design enables an HT core to run two independent threads, while requiring fewer transistors than a dual core CPU, thanks to the shared back end and L1 cache. Of course, this sharing of hardware components also results in lower instruction throughput relative to a comparable dual core CPU, because the threads contend for these shared resources.

![[Pasted image 20221124213711.png]]
*A hyperthreaded CPU containing two front ends (each consisting of a fetch/decode unit and a register file), but with a single back end containing ALUs, FPUs, a memory controller, an L1 cache, and an out-of-order instruction scheduler. The scheduler issues instructions from both front-end threads to the shared back-end components.*